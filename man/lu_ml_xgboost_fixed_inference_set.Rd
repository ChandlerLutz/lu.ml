% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/lu_ml_xgboost_fixed_inference_set.R
\name{lu_ml_xgboost_fixed_inference_set}
\alias{lu_ml_xgboost_fixed_inference_set}
\title{Perform XGBoost Prediction with Fixed Inference Groups}
\usage{
lu_ml_xgboost_fixed_inference_set(DT.hp, DT.lu, seed = 123)
}
\arguments{
\item{DT.hp}{A \code{data.table} containing the target variable and grouping information.
It must include the following columns:
\itemize{
\item \code{GEOID}: A unique identifier for each location.
\item \code{index}: A \code{Date} object representing the time period.
\item \code{inference.grp}: A character vector defining the cross-validation group
for each \code{GEOID}.
\item \code{hp.target}: A numeric vector representing the target variable for the model.
}}

\item{DT.lu}{A \code{data.table} containing time-invariant features for each \code{GEOID}.
It must have a \code{GEOID} column for merging with \code{DT.hp}. Feature columns to be
used in the model must contain the pattern \code{"unavailable"} in their names.}

\item{seed}{An integer used to set the seed for reproducibility. Defaults to \code{123}.}
}
\value{
A \code{data.table} that includes the original columns of \code{DT.hp} plus a
new column, \code{lu_ml_xgboost}, which contains the out-of-sample XGBoost predictions.
}
\description{
This function trains an XGBoost model and generates out-of-sample (OOS)
predictions for specified groups of observations. The process is repeated
for each unique time point in the dataset. It uses a leave-group-out
cross-validation strategy where, for each time point, one group is held out
for inference while the remaining groups are used for training.
}
\details{
The function operates independently for each time period specified in the \code{index}
column of \code{DT.hp}. For each period, it performs the following steps:
\enumerate{
\item \strong{Grouping}: It uses the \code{inference.grp} column to define distinct groups of
\code{GEOID}s.
\item \strong{Leave-Group-Out CV}: For each group, it holds out all associated \code{GEOID}s
as the inference set. The data from all other groups becomes the training set.
\item \strong{Hyperparameter Tuning}: The training set is further split into a sub-training
set (75\%) and a validation set (25\%) to find the optimal number of boosting
rounds (\code{nrounds}). This is achieved using XGBoost's early stopping mechanism
(with \code{early_stopping_rounds = 25}) to prevent overfitting.
\item \strong{Model Training}: A final XGBoost model is trained on the entire training
set using the optimal \code{nrounds} determined in the previous step.
\item \strong{Prediction}: The trained model is used to generate predictions for the
held-out inference set.
\item \strong{Parallel Execution}: This entire process is parallelized across the
different inference groups for each time period using the \code{future} framework.
}

The final output is a \code{data.table} that merges these OOS predictions back with
the original input data. Note that the function automatically identifies predictor
variables in \code{DT.lu} by searching for column names containing the pattern
\code{"unavailable"}. It also removes any columns with the suffix \code{saiz.circle}
before training.
}
\examples{
\dontrun{
library(data.table)

# --- 0. Load sample datasets ---
# These would typically be loaded from your data package.
data(dt_mian_sufi_2014)
data(dt_cnty_lu_2010)

# --- 1. Prepare the house price data (DT.hp) ---
# Select relevant columns, rename them, and handle missing values.
DT.hp <- dt_mian_sufi_2014[, .(
  GEOID = fips,
  index = as.Date("2002-01-01"),
  hp.target = house.net.worth
)][!is.na(hp.target)]

# Add the required 'inference.grp' column. For this example, we'll use
# each GEOID as its own group, effectively performing leave-one-out CV.
DT.hp[, inference.grp := as.character(GEOID)]
setcolorder(DT.hp, c("GEOID", "index", "inference.grp", "hp.target"))


# --- 2. Prepare the land use feature data (DT.lu) ---
# The function automatically selects columns with "unavailable" in the name.
# We subset the data to keep only GEOID and those feature columns.
feature_cols <- grep("unavailable", names(dt_cnty_lu_2010), value = TRUE)
DT.lu <- dt_cnty_lu_2010[, .SD, .SDcols = c("GEOID", feature_cols)]


# --- 3. Run the function ---
predictions <- lu_ml_xgboost_fixed_inference_set(
  DT.hp = DT.hp,
  DT.lu = DT.lu,
  seed = 123
)

# --- 4. View and verify the results ---
print(head(predictions))
}
}
